{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfaafb66044e298",
   "metadata": {},
   "source": [
    "This is a adaptation of PyTorch reimplementation of RISE from this repository: https://github.com/yiskw713/RISE\n",
    "\n",
    "The RISE code has been modified and adapted to work with models with tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fd5cba47c01d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T13:21:19.901505Z",
     "start_time": "2025-04-30T13:21:19.898898Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from rise import CXR_RISE\n",
    "from utils.visualize import visualize, reverse_normalize\n",
    "import sys\n",
    "\n",
    "project_root = \"/home/wasabi/PycharmProjects/cs-7643-final-project\"\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from src.models.cxr_model import CXRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5185b2c7bde448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T13:21:20.416033Z",
     "start_time": "2025-04-30T13:21:20.384566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose a X-Ray to analyze and paste it's Path\n",
    "image = Image.open('/home/wasabi/PycharmProjects/cs-7643-final-project/artifacts/embedded_test/00000661_001.png')\n",
    "\n",
    "# Choose the targeted Outcome Class Index\n",
    "target_class = 1\n",
    "\n",
    "\n",
    "image = image.convert('RGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb222139b598bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T13:21:20.659030Z",
     "start_time": "2025-04-30T13:21:20.655111Z"
    }
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee7283ee855eb8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T13:21:20.829291Z",
     "start_time": "2025-04-30T13:21:20.819834Z"
    }
   },
   "outputs": [],
   "source": [
    "tensor = preprocess(image).unsqueeze(0)\n",
    "_, _, H, W = tensor.shape\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tensor = tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ec81286b3b55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T13:21:22.038188Z",
     "start_time": "2025-04-30T13:21:20.994983Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_path = 'embd_vit_b_32_lr_1e-05_bs_32_do_0.2_hd_None_ms_32_best.pth'\n",
    "# model_path = 'vit_b_32_lr_1e-05_bs_32_do_0.2_hd_(512, 256, 128, 64, 32)_best.pth'\n",
    "model_path = '/tmp/cs7643_final_share/emad_results/best_model_vit_b_32_embedded_focal.pth'\n",
    "\n",
    "save_info = torch.load(model_path)\n",
    "print(save_info[\"config\"])\n",
    "model = CXRModel(**save_info[\"config\"])\n",
    "model.load_state_dict(save_info[\"model\"])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33928d0db8b42d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T13:21:25.105942Z",
     "start_time": "2025-04-30T13:21:22.233243Z"
    }
   },
   "outputs": [],
   "source": [
    "tabular_data = torch.tensor([[0.5, 0.5, 0.5, 0.0]])\n",
    "\n",
    "wrapped_model = CXR_RISE(model, tabular_data, input_size=(H, W))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2058c0b8cd4360",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-30T13:21:25.191144Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(target_class)\n",
    "with torch.no_grad():\n",
    "    saliency = wrapped_model(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c737544d084d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = saliency[target_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d817365825b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = reverse_normalize(tensor.to('cpu'))\n",
    "saliency = saliency.view(1, 1, H, W)\n",
    "heatmap = visualize(img, saliency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a271e90dcf193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(heatmap, 'class_cardiomegaly_explanation_new.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7643-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
